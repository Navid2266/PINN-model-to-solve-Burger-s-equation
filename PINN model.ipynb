{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN (nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(2, 50)] + [nn.Linear(50, 50) for _ in range(7)])\n",
    "        self.output_layer = nn.Linear(50, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=1.0)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        inputs = torch.cat([x, t], axis=1)\n",
    "        outputs = self.activation(self.hidden_layers[0](inputs))\n",
    "        for layer in self.hidden_layers[1:]:\n",
    "            outputs = self.activation(layer(outputs))\n",
    "        output = self.output_layer(outputs)\n",
    "        return output\n",
    "\n",
    "model1 = PINN()\n",
    "optimizer = torch.optim.Adam(model1.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = (0.0,)\n",
    "v = Params[0] \n",
    "x0 = 0\n",
    "x1 = 1\n",
    "t0 = 0 \n",
    "t1 = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Points and Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PDE_Data(x_0, x_1, t_0, t_1, n):\n",
    "    # PDE points \n",
    "    xx = x_1 - x_0 \n",
    "    # using Sobol sequence to achieve more even distribution \n",
    "    x = xx*torch.quasirandom.SobolEngine(dimension=1).draw(n, dtype=torch.float32) + x_0\n",
    "    x.requires_grad_(False)\n",
    "\n",
    "    t = torch.quasirandom.SobolEngine(dimension=1)\n",
    "    t = t.draw(n, dtype=torch.float32)\n",
    "    tt = t_1 - t_0\n",
    "    t = tt * t\n",
    "    t = t + t_0\n",
    "    t.requires_grad_(False)\n",
    "\n",
    "\n",
    "    PDE_points = torch.stack((x, t, torch.zeros(n,1,requires_grad=False)), dim=0)\n",
    "\n",
    "    return PDE_points\n",
    "\n",
    "def PDE_cost (Data,model,Param):\n",
    "    x = Data[0,:]\n",
    "    t = Data[1,:]\n",
    "\n",
    "    x = x.clone().requires_grad_(True)\n",
    "    t = t.clone().requires_grad_(True)\n",
    "    u = model(x, t)\n",
    "    du_dx = torch.autograd.grad(u.sum(), x, create_graph=True, retain_graph=True)[0]\n",
    "    du_dt = torch.autograd.grad(u.sum(), t, create_graph=True, retain_graph=True)[0]\n",
    "    d2u_dx2 = torch.autograd.grad(du_dx.sum(), x, create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    PDE_loss = du_dt + u * du_dx - Param * d2u_dx2\n",
    "    \n",
    "    z = torch.nn.MSELoss()\n",
    "    loss = z(PDE_loss,Data[2,:])\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda1 (x_BC,t_BC):\n",
    "    return torch.zeros_like(x_BC,requires_grad=False)\n",
    "\n",
    "def BC_Data (x_b,t_0,t_1,func,n):\n",
    "    x_BC = torch.ones(n,1,requires_grad=False)\n",
    "    x_BC = x_BC * x_b\n",
    "\n",
    "    t_collocation_Sobol = torch.quasirandom.SobolEngine(dimension=1)\n",
    "    t_collocation1 = t_collocation_Sobol.draw(n,dtype=torch.float32)\n",
    "    tt = t_1 - t_0\n",
    "    t_BC = tt * t_collocation1\n",
    "    t_BC = t_BC + t_0\n",
    "    t_BC.requires_grad_(False)\n",
    "\n",
    "    v = func(x_BC,t_BC)\n",
    "    BC_points = torch.stack((x_BC,t_BC,v),axis=0)\n",
    "    return BC_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda2 (x_IC,t_IC):\n",
    "    return torch.sin(torch.pi * 2 * x_IC).requires_grad_(False)\n",
    "\n",
    "def IC_Data (x_0,x_1,t_i,func,n):\n",
    "    \n",
    "    x_sobol = torch.quasirandom.SobolEngine(dimension=1)\n",
    "    x_IC = x_sobol.draw(n,dtype=torch.float32)\n",
    "    xx = x_1 - x_0\n",
    "    x_IC = x_IC * xx\n",
    "    x_IC = x_IC + x_0\n",
    "    x_IC.requires_grad_(False)\n",
    "\n",
    "    t_IC = torch.ones(n,1,requires_grad=False)\n",
    "    t_IC = t_IC * t_i\n",
    "\n",
    "    v = func(x_IC,t_IC)\n",
    "\n",
    "    IC_points = torch.stack((x_IC,t_IC,v),axis=0)\n",
    "    return IC_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost (Data,model):\n",
    "    \n",
    "    #define the cost method \n",
    "    cost_function = torch.nn.MSELoss()\n",
    "    return cost_function(Data[2,:],model(Data[0,:],Data[1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analythical Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Answers_equation (u,x,t):\n",
    "    return u - np.sin(2*np.pi*(x-u*t))\n",
    "\n",
    "def validation (x,t,func,n):\n",
    "    t_value = t\n",
    "    x1 = x\n",
    "    x1 = np.sort(x1)\n",
    "    x1 = x1.reshape(n,1)\n",
    "    solution = np.zeros(x1.shape)\n",
    "    x_values = np.zeros(x1.shape)\n",
    "\n",
    "    for i , x_values in enumerate(x1[1:]):\n",
    "        solution[i] = fsolve(func,solution[i-1],args=(x_values,t_value))\n",
    "\n",
    "    print(x_values.shape)\n",
    "    \n",
    "    for i,x_values in enumerate(x1):\n",
    "        print (f\"solution at x={x_values} and t={t_value} is u={solution[i]}\")\n",
    "   \n",
    "    return solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10000\n",
    "\n",
    "BC1_Points = BC_Data(x0,t0,t1,lambda1,500)\n",
    "BC2_Points = BC_Data(x1,t0,t1,lambda1,500)\n",
    "IC_Points = IC_Data(x0,x1,t0,lambda2,500)\n",
    "PDE_Points = PDE_Data(x0,x1,t0,t1,3000)\n",
    "\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range (iterations):\n",
    "    optimizer.zero_grad()\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    #BC loss\n",
    "    BC1_loss = cost(BC1_Points,model1)\n",
    "    BC2_loss = cost(BC2_Points,model1)\n",
    "\n",
    "    #IC loss\n",
    "    IC_loss = cost(IC_Points,model1)\n",
    "\n",
    "    #PDE loss\n",
    "    #PDE_Points = PDE_Data(0,1,0,0.5,model1,v,100)\n",
    "    #PDE_loss = PDE_Points[2,:,0].reshape(100,1)\n",
    "    PDE_loss = PDE_cost(PDE_Points,model1,v)\n",
    "\n",
    "    #total loss\n",
    "    loss = BC1_loss + BC2_loss + IC_loss + PDE_loss\n",
    "\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.autograd.no_grad():\n",
    "        print(epoch,\"Training Loss:\",loss.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = PDE_Data(0,1,0,0.1,500)\n",
    "x1 = data1[0,:,0].detach().numpy()\n",
    "t1 = 0.1\n",
    "analytical_solution = validation(x1,t1,Answers_equation,500)\n",
    "x1 = np.sort(x1)\n",
    "\n",
    "# Plot the analythical answer graph only\n",
    "plt.plot(x1, analytical_solution, label='Function Curve')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Graph of Y vs. X')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "x3 = torch.linspace(0,1,100).reshape(100,1)\n",
    "t = 0.1 * torch.ones(100,1,requires_grad=False).reshape(100,1)\n",
    "\n",
    "final = model1(x3,t)\n",
    "\n",
    "x_graph = x3.detach().numpy()\n",
    "answer_graph = final.detach().numpy()\n",
    "\n",
    "# Plot the model and analythical answer graph\n",
    "plt.plot(x3, answer_graph, label='Function Curve')\n",
    "plt.plot(x1, analytical_solution, label='Analytical Curve')\n",
    "plt.scatter(x3, answer_graph, color='red', label='Data Points')  # Scatter plot for data points\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Graph of Y vs. X')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
